{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPO9eNYbTvVpoZluobZwHrY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://towardsdatascience.com/paper-walkthrough-vision-transformer-vit-c5dcf76f1a7a)"
      ],
      "metadata": {
        "id": "WMuiwi9cgY4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INZF9GnHiIHn",
        "outputId": "d129a8cf-0d4e-4cbe-9fb0-338ccbcdbf55"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_Th-14FcgRKd"
      },
      "outputs": [],
      "source": [
        "# Codeblock 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 2\n",
        "#(1)\n",
        "BATCH_SIZE   = 1\n",
        "IMAGE_SIZE   = 224\n",
        "IN_CHANNELS  = 3\n",
        "\n",
        "#(2)\n",
        "PATCH_SIZE   = 16\n",
        "NUM_HEADS    = 12\n",
        "NUM_ENCODERS = 12\n",
        "EMBED_DIM    = 768\n",
        "MLP_SIZE     = EMBED_DIM * 4    # 768*4 = 3072\n",
        "\n",
        "#(3)\n",
        "NUM_PATCHES  = (IMAGE_SIZE//PATCH_SIZE) ** 2    # (224//16)**2 = 196\n",
        "\n",
        "#(4)\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_CLASSES  = 10"
      ],
      "metadata": {
        "id": "As_xGML4hNoC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UhZwqiwhR5u",
        "outputId": "4a712cca-6043-4097-e020-a41a4b341d0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 4\n",
        "class PatcherUnfold(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unfold = nn.Unfold(kernel_size=PATCH_SIZE, stride=PATCH_SIZE)    #(1)\n",
        "        self.linear_projection = nn.Linear(in_features=IN_CHANNELS*PATCH_SIZE*PATCH_SIZE,\n",
        "                                           out_features=EMBED_DIM)    #(2)\n",
        "    # Codeblock 5\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t: {x.size()}')\n",
        "\n",
        "        x = self.unfold(x)\n",
        "        print(f'after unfold\\t: {x.size()}')\n",
        "\n",
        "        x = x.permute(0, 2, 1)    #(1)\n",
        "        print(f'after permute\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_projection(x)\n",
        "        print(f'after lin proj\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "4e53NZofhiJS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 6\n",
        "patcher_unfold = PatcherUnfold()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "x = patcher_unfold(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2F-BtvwhjUF",
        "outputId": "c7b76c59-bdae-4ace-d49d-ad2da6e478da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t: torch.Size([1, 3, 224, 224])\n",
            "after unfold\t: torch.Size([1, 768, 196])\n",
            "after permute\t: torch.Size([1, 196, 768])\n",
            "after lin proj\t: torch.Size([1, 196, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 7\n",
        "class PatcherConv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=IN_CHANNELS,\n",
        "                              out_channels=EMBED_DIM,\n",
        "                              kernel_size=PATCH_SIZE,\n",
        "                              stride=PATCH_SIZE)\n",
        "\n",
        "        self.flatten = nn.Flatten(start_dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.conv(x)    #(1)\n",
        "        print(f'after conv\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.flatten(x)    #(2)\n",
        "        print(f'after flatten\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x.permute(0, 2, 1)    #(3)\n",
        "        print(f'after permute\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "28U2_nWDhoYo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 8\n",
        "patcher_conv = PatcherConv()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "x = patcher_conv(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBTlJ6sXhrZn",
        "outputId": "e0028efb-d3c0-4a9e-df5b-7130e020cbb7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 9\n",
        "class PosEmbedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.class_token = nn.Parameter(torch.randn(size=(BATCH_SIZE, 1, EMBED_DIM)),\n",
        "                                        requires_grad=True)    #(1)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(size=(BATCH_SIZE, NUM_PATCHES+1, EMBED_DIM)),\n",
        "                                          requires_grad=True)    #(2)\n",
        "        self.dropout = nn.Dropout(p=DROPOUT_RATE)  #(3)\n",
        "    # Codeblock 10\n",
        "    def forward(self, x):\n",
        "\n",
        "        class_token = self.class_token\n",
        "        print(f'class_token dim\\t\\t: {class_token.size()}')\n",
        "\n",
        "        print(f'before concat\\t\\t: {x.size()}')\n",
        "        x = torch.cat([class_token, x], dim=1)    #(1)\n",
        "        print(f'after concat\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.pos_embedding + x    #(2)\n",
        "        print(f'after pos_embedding\\t: {x.size()}')\n",
        "\n",
        "        x = self.dropout(x)    #(3)\n",
        "        print(f'after dropout\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "52voj2iKhsyv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 11\n",
        "pos_embedding = PosEmbedding()\n",
        "x = pos_embedding(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vE2__pshuWt",
        "outputId": "85c6864b-84f0-4d8b-8240-2bfcc1b5bd56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 12\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm_0 = nn.LayerNorm(EMBED_DIM)    #(1)\n",
        "\n",
        "        self.multihead_attention = nn.MultiheadAttention(EMBED_DIM,    #(2)\n",
        "                                                         num_heads=NUM_HEADS,\n",
        "                                                         batch_first=True,\n",
        "                                                         dropout=DROPOUT_RATE)\n",
        "\n",
        "        self.norm_1 = nn.LayerNorm(EMBED_DIM)    #(3)\n",
        "\n",
        "        self.mlp = nn.Sequential(    #(4)\n",
        "            nn.Linear(in_features=EMBED_DIM, out_features=MLP_SIZE),    #(5)\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=DROPOUT_RATE),\n",
        "            nn.Linear(in_features=MLP_SIZE, out_features=EMBED_DIM),    #(6)\n",
        "            nn.Dropout(p=DROPOUT_RATE)\n",
        "        )\n",
        "\n",
        "    # Codeblock 13\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x    #(1)\n",
        "        print(f'residual dim\\t\\t: {residual.size()}')\n",
        "\n",
        "        x = self.norm_0(x)    #(2)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.multihead_attention(x, x, x)[0]    #(3)\n",
        "        print(f'after attention\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x + residual    #(4)\n",
        "        print(f'after addition\\t\\t: {x.size()}')\n",
        "\n",
        "        residual = x    #(5)\n",
        "        print(f'residual dim\\t\\t: {residual.size()}')\n",
        "\n",
        "        x = self.norm_1(x)    #(6)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.mlp(x)    #(7)\n",
        "        print(f'after mlp\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x + residual    #(8)\n",
        "        print(f'after addition\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "TyEnJjochzjx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 14\n",
        "transformer_encoder = TransformerEncoder()\n",
        "x = transformer_encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu9j5IkCh0ux",
        "outputId": "21c1fb6e-645a-4d03-c515-8aa278a089af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 15\n",
        "class MLPHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.LayerNorm(EMBED_DIM)\n",
        "        self.linear_0 = nn.Linear(in_features=EMBED_DIM,\n",
        "                                  out_features=EMBED_DIM)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.linear_1 = nn.Linear(in_features=EMBED_DIM,\n",
        "                                  out_features=NUM_CLASSES)    #(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.norm(x)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_0(x)\n",
        "        print(f'after layer_0 mlp\\t: {x.size()}')\n",
        "\n",
        "        x = self.gelu(x)\n",
        "        print(f'after gelu\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        print(f'after layer_1 mlp\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "P0NfQPlwh4OC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 16\n",
        "x = x[:, 0]    #(1)\n",
        "mlp_head = MLPHead()\n",
        "x = mlp_head(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT8_zyv0h5sU",
        "outputId": "6a024584-cbad-4298-c7e2-20109a74c966"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 17\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.patcher = PatcherUnfold()\n",
        "        self.patcher = PatcherConv()    #(1)\n",
        "        self.pos_embedding = PosEmbedding()\n",
        "        self.transformer_encoders = nn.Sequential(\n",
        "            *[TransformerEncoder() for _ in range(NUM_ENCODERS)]    #(2)\n",
        "            )\n",
        "        self.mlp_head = MLPHead()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.patcher(x)\n",
        "        x = self.pos_embedding(x)\n",
        "        x = self.transformer_encoders(x)\n",
        "        x = x[:, 0]    #(3)\n",
        "        x = self.mlp_head(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "OLXF51rkh6m1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 18\n",
        "vit = ViT().to(device)\n",
        "x = torch.randn(1, 3, 224, 224).to(device)\n",
        "print(vit(x).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miLzodc9h773",
        "outputId": "f9d77b6c-67b1-42dc-b389-bb93adf1d124"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n",
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codeblock 19\n",
        "summary(vit, input_size=(1,3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC-6lN3hh9iu",
        "outputId": "a5abae4e-075c-4c31-af8e-399887a2452f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n",
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ViT                                      [1, 10]                   --\n",
              "├─PatcherConv: 1-1                       [1, 196, 768]             --\n",
              "│    └─Conv2d: 2-1                       [1, 768, 14, 14]          590,592\n",
              "│    └─Flatten: 2-2                      [1, 768, 196]             --\n",
              "├─PosEmbedding: 1-2                      [1, 197, 768]             152,064\n",
              "│    └─Dropout: 2-3                      [1, 197, 768]             --\n",
              "├─Sequential: 1-3                        [1, 197, 768]             --\n",
              "│    └─TransformerEncoder: 2-4           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-1               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-2      [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-3               [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-4              [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-5           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-5               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-6      [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-7               [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-8              [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-6           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-9               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-10     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-11              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-12             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-7           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-13              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-14     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-15              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-16             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-8           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-17              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-18     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-19              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-20             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-9           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-21              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-22     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-23              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-24             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-10          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-25              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-26     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-27              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-28             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-11          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-29              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-30     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-31              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-32             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-12          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-33              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-34     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-35              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-36             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-13          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-37              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-38     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-39              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-40             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-14          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-41              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-42     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-43              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-44             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-15          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-45              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-46     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-47              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-48             [1, 197, 768]             4,722,432\n",
              "├─MLPHead: 1-4                           [1, 10]                   --\n",
              "│    └─LayerNorm: 2-16                   [1, 768]                  1,536\n",
              "│    └─Linear: 2-17                      [1, 768]                  590,592\n",
              "│    └─GELU: 2-18                        [1, 768]                  --\n",
              "│    └─Linear: 2-19                      [1, 10]                   7,690\n",
              "==========================================================================================\n",
              "Total params: 86,396,938\n",
              "Trainable params: 86,396,938\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 173.06\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 102.89\n",
              "Params size (MB): 231.59\n",
              "Estimated Total Size (MB): 335.08\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}