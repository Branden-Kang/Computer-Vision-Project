{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN576SRN8EKpjqlI1Y+xJXY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@nandinilreddy/yolo-v12-visual-prompt-chaining-1ebdf8800a46)"
      ],
      "metadata": {
        "id": "QmkanF54ZE1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q ultralytics"
      ],
      "metadata": {
        "id": "YqMsxcvLZlUh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define object tracker class"
      ],
      "metadata": {
        "id": "7KXH1TPOZm20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "PoM9YY4bY_Fo",
        "outputId": "1354801c-cb63-4d22-9257-5028a819a05e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1029310114>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import time\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "class ObjectTracker:\n",
        "    def __init__(self, buffer_seconds=60.0):\n",
        "        \"\"\"Initialize the object tracker with a time buffer\"\"\"\n",
        "        self.detection_history = deque(maxlen=30)\n",
        "        self.buffer_time = buffer_seconds\n",
        "\n",
        "    def process_detection(self, image, model):\n",
        "        \"\"\"Process an image with YOLO and track the detection sequence\"\"\"\n",
        "        results = model(image)[0]\n",
        "        current_time = time.time()\n",
        "        detections = []\n",
        "        for box in results.boxes.data.tolist():\n",
        "            x1, y1, x2, y2, conf, class_id = box\n",
        "            class_id = int(class_id)\n",
        "            class_name = model.names[class_id]\n",
        "\n",
        "            detections.append({\n",
        "                'class_name': class_name,\n",
        "                'confidence': conf,\n",
        "                'box': [x1, y1, x2, y2]\n",
        "            })\n",
        "        if detections:\n",
        "            self.detection_history.append({\n",
        "                'timestamp': current_time,\n",
        "                'detections': detections.copy()\n",
        "            })\n",
        "            self._clean_history(current_time)\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def _clean_history(self, current_time):\n",
        "        \"\"\"Remove detections older than buffer_time\"\"\"\n",
        "        while (self.detection_history and\n",
        "               current_time - self.detection_history[0]['timestamp'] > self.buffer_time):\n",
        "            self.detection_history.popleft()\n",
        "\n",
        "    def get_raw_detection_sequence(self):\n",
        "        \"\"\"Get the complete sequence of all detections in order, with duplicates\"\"\"\n",
        "        sequence = []\n",
        "\n",
        "        for entry in self.detection_history:\n",
        "            for det in entry['detections']:\n",
        "                sequence.append({\n",
        "                    'class_name': det['class_name'],\n",
        "                    'confidence': det['confidence'],\n",
        "                    'timestamp': entry['timestamp']\n",
        "                })\n",
        "        sequence.sort(key=lambda x: x['timestamp'])\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    def get_unique_objects_sequence(self):\n",
        "        \"\"\"Get unique objects in order of first appearance\"\"\"\n",
        "        sequence = []\n",
        "        seen = set()\n",
        "\n",
        "        for entry in self.detection_history:\n",
        "            for det in entry['detections']:\n",
        "                class_name = det['class_name']\n",
        "                if class_name not in seen:\n",
        "                    sequence.append(class_name)\n",
        "                    seen.add(class_name)\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    def get_confidence_weighted_objects(self):\n",
        "        \"\"\"Get objects weighted by their detection confidence\"\"\"\n",
        "        confidence_map = {}\n",
        "\n",
        "        for entry in self.detection_history:\n",
        "            for det in entry['detections']:\n",
        "                class_name = det['class_name']\n",
        "                confidence = det['confidence']\n",
        "\n",
        "                if class_name not in confidence_map or confidence > confidence_map[class_name]:\n",
        "                    confidence_map[class_name] = confidence\n",
        "\n",
        "        sorted_objects = sorted(confidence_map.items(), key=lambda x: x[1], reverse=True)\n",
        "        return sorted_objects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define GPT response generator"
      ],
      "metadata": {
        "id": "Tw9fcIs5Zp9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gpt_response(sequence, user_profile=None):\n",
        "    \"\"\"Generate a response from GPT based on detected objects\"\"\"\n",
        "    if user_profile is None:\n",
        "        user_profile = {\n",
        "            \"name\": \"Nandini\",\n",
        "            \"profession\": \"Data Scientist\",\n",
        "            \"interests\": [\"computer vision\", \"machine learning\", \"data analysis\"]\n",
        "        }\n",
        "\n",
        "    # STEP 2.1: Get API key from environment variable\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # Check if API key exists\n",
        "    if not api_key:\n",
        "        print(\"\\nError: OpenAI API key not found!\")\n",
        "        print(\"Please set your API key as an environment variable:\")\n",
        "        print(\"  For Windows: set OPENAI_API_KEY=your-api-key-here\")\n",
        "        print(\"  For macOS/Linux: export OPENAI_API_KEY=your-api-key-here\")\n",
        "        return \"Error: API key not configured. See console for instructions.\"\n",
        "\n",
        "    try:\n",
        "        # STEP 2.2: Initialize the OpenAI client with the API key\n",
        "        client = OpenAI(api_key=api_key)\n",
        "\n",
        "        # STEP 2.3: Create system prompt for GPT\n",
        "        system_message = f\"\"\"\n",
        "        You are a helpful AI assistant integrated with a computer vision system.\n",
        "        You're talking to {user_profile['name']}, who works as a {user_profile['profession']}.\n",
        "        Be friendly and personable.\n",
        "\n",
        "        When you see work-related objects, share recent interesting AI developments.\n",
        "        When you see everyday objects, provide practical insights.\n",
        "\n",
        "        Keep your response under 150 words and make it conversational.\n",
        "        \"\"\"\n",
        "\n",
        "        # STEP 2.4: Get current time for context\n",
        "        current_datetime = datetime.now().strftime(\"%A, %B %d, %Y at %I:%M %p\")\n",
        "\n",
        "        # STEP 2.5: Generate dynamic prompt based on detected objects\n",
        "        objects_str = \", \".join(sequence)\n",
        "        prompt = f\"\"\"\n",
        "        Based on the objects I can see ({objects_str}), generate a relevant response\n",
        "        that considers my current context. What interesting AI developments or insights\n",
        "        might be relevant to my current environment? Please be specific to what you can see.\n",
        "        \"\"\"\n",
        "\n",
        "        # STEP 2.6: Build the messages for the GPT API\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"\n",
        "            The computer vision system has detected: {', '.join(sequence)}\n",
        "            Current time: {current_datetime}\n",
        "\n",
        "            {prompt}\n",
        "            \"\"\"}\n",
        "        ]\n",
        "\n",
        "        print(f\"\\nSending request to GPT with detected objects: {sequence}\")\n",
        "\n",
        "        # STEP 2.7: Call the GPT API\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        # STEP 2.8: Extract and return the response\n",
        "        gpt_response = response.choices[0].message.content\n",
        "        return gpt_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError generating GPT response: {e}\")\n",
        "        return f\"Error: Could not generate GPT response. {str(e)}\""
      ],
      "metadata": {
        "id": "_KEHK5ZJZpF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "ktjd8kk9Zt7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the object detection and GPT response pipeline\"\"\"\n",
        "    print(\"Starting Object Detection to GPT Pipeline...\")\n",
        "\n",
        "    # STEP 3.1: Load the YOLO model\n",
        "    print(\"Loading YOLO model...\")\n",
        "    try:\n",
        "        model = YOLO('yolo12n.pt')\n",
        "        print(\"YOLO model loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading YOLO model: {e}\")\n",
        "        return\n",
        "\n",
        "    # STEP 3.2: Load the image\n",
        "    image_path = 'image2.png'\n",
        "    print(f\"Loading image from: {image_path}\")\n",
        "\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Error: Could not load image at {image_path}\")\n",
        "            print(\"Make sure the image file exists in the current directory\")\n",
        "            return\n",
        "        print(\"Image loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return\n",
        "\n",
        "    # STEP 3.3: Initialize the object tracker\n",
        "    print(\"Initializing object tracker...\")\n",
        "    tracker = ObjectTracker()\n",
        "\n",
        "    # STEP 3.4: Process the detection with the tracker\n",
        "    print(\"Processing image with YOLO...\")\n",
        "    detections = tracker.process_detection(image, model)\n",
        "\n",
        "    if not detections:\n",
        "        print(\"No objects detected in the image\")\n",
        "        return\n",
        "\n",
        "    # STEP 3.5: Get different representations of the detection sequence\n",
        "    print(\"\\nExtracting detection sequences...\")\n",
        "    raw_sequence = tracker.get_raw_detection_sequence()\n",
        "    unique_sequence = tracker.get_unique_objects_sequence()\n",
        "    confidence_weighted = tracker.get_confidence_weighted_objects()\n",
        "\n",
        "    # STEP 3.6: Display detection results\n",
        "    print(\"\\n--- Detection Results ---\")\n",
        "    print(\"\\nRaw detection sequence:\")\n",
        "    for det in raw_sequence:\n",
        "        print(f\"{det['class_name']} (confidence: {det['confidence']:.2f})\")\n",
        "\n",
        "    print(\"\\nUnique objects in order of appearance:\")\n",
        "    print(unique_sequence)\n",
        "\n",
        "    print(\"\\nObjects by confidence:\")\n",
        "    for obj, conf in confidence_weighted:\n",
        "        print(f\"{obj}: {conf:.2f}\")\n",
        "\n",
        "    # STEP 3.7: Visualize the results with matplotlib\n",
        "    print(\"\\nGenerating visualization...\")\n",
        "    try:\n",
        "        annotated_image = model(image)[0].plot()\n",
        "        annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(annotated_image_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.title('Detected Objects')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating visualization: {e}\")\n",
        "\n",
        "    # STEP 3.8: Generate GPT response if objects were detected\n",
        "    if unique_sequence:\n",
        "        print(\"\\nGenerating GPT response based on detected objects...\")\n",
        "\n",
        "        user_profile = {\n",
        "            \"name\": \"Nandini\",\n",
        "            \"profession\": \"Data Scientist\",\n",
        "            \"interests\": [\"computer vision\", \"machine learning\", \"data analysis\"]\n",
        "        }\n",
        "\n",
        "        response = generate_gpt_response(unique_sequence, user_profile)\n",
        "        print(\"\\n--- GPT Response Based on Detected Objects ---\")\n",
        "        print(response)\n",
        "        print(\"\\n--- End of Pipeline ---\")\n",
        "    else:\n",
        "        print(\"No objects detected to generate a GPT response\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "23zw_YHDZtBg"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}
