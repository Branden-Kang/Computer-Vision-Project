{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNS+XFgD/gOoN+6ezUTqYKN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@pankaj_pandey/16f5d285c38d)"
      ],
      "metadata": {
        "id": "w2AXUnD2Pnxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y1GYf2BGPQzD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "train_seg_head.py â€” Minimal training loop on frozen DINOv3 features.\n",
        "Replace `YourDataset` with ADE20K/Cityscapes/etc. (images, masks).\n",
        "\"\"\"\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModel, AutoImageProcessor\n",
        "\n",
        "MODEL_ID = \"facebook/dinov3-vitb16-pretrain-lvd1689m\"\n",
        "N_CLASSES = 150\n",
        "class LinearSegHead(nn.Module):\n",
        "    def __init__(self, in_ch, n_classes):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(in_ch, n_classes, 1)\n",
        "        self.up = nn.Upsample(scale_factor=16, mode=\"bilinear\", align_corners=False)\n",
        "    def forward(self, fmap): return self.up(self.proj(fmap))\n",
        "def extract_fmap(model, proc, image):\n",
        "    inputs = proc(images=image, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.inference_mode():\n",
        "        out = model(**inputs)\n",
        "    num_regs = model.config.num_register_tokens\n",
        "    grid = out.last_hidden_state[:, 1 + num_regs:, :]  # drop CLS+registers\n",
        "    B, N, C = grid.shape\n",
        "    H = W = int(N ** 0.5)\n",
        "    return grid.reshape(B, H, W, C).permute(0,3,1,2)\n",
        "def main(train_set, val_set, epochs=10, lr=1e-3):\n",
        "    proc = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "    model = AutoModel.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
        "    for p in model.parameters(): p.requires_grad_(False)\n",
        "    # infer channels once\n",
        "    x0, _ = train_set[0]\n",
        "    fmap0 = extract_fmap(model, proc, x0)\n",
        "    head = LinearSegHead(fmap0.shape[1], N_CLASSES).to(model.device)\n",
        "    opt = optim.AdamW(head.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    train = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "    val = DataLoader(val_set, batch_size=4)\n",
        "    for ep in range(epochs):\n",
        "        head.train()\n",
        "        for img, mask in train:\n",
        "            fmap = extract_fmap(model, proc, img)\n",
        "            logits = head(fmap)\n",
        "            L = loss(logits, mask.to(logits.device).long())\n",
        "            opt.zero_grad(); L.backward(); opt.step()\n",
        "        # TODO: add simple mIoU on `val`\n",
        "    torch.save(head.state_dict(), \"dinov3_seg_head.pth\")"
      ]
    }
  ]
}