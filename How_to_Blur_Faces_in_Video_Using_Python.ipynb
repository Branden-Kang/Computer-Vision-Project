{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME/kTmZQQ4jBd8eL8UgKQY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@fareedkhandev/how-to-blur-faces-in-video-using-python-4b84d59ea6ad)"
      ],
      "metadata": {
        "id": "g-VzjokXGiT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKrFoKtsGhKY"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import mediapipe as mp\n",
        "# import time\n",
        "\n",
        "# cap = cv2.VideoCapture(\"input_video.mp4\")\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# out = cv2.VideoWriter('output_video.avi', fourcc, 25, (1920, 1080))\n",
        "\n",
        "# pTime = 0\n",
        "\n",
        "# mpFaceDetection = mp.solutions.face_detection\n",
        "# mpDraw = mp.solutions.drawing_utils\n",
        "# faceDetection = mpFaceDetection.FaceDetection(0.75)\n",
        "\n",
        "# while True:\n",
        "#     success, img = cap.read()\n",
        "#     width  = 1920 \n",
        "#     height = 1080\n",
        "#     img = cv2.resize(img, (width, height))\n",
        "#     imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#     results = faceDetection.process(imgRGB)\n",
        "#     print(results)\n",
        "\n",
        "#     if results.detections:\n",
        "#         for id, detection in enumerate(results.detections):\n",
        "#             # mpDraw.draw_detection(img, detection)\n",
        "#             # print(id, detection)\n",
        "#             # print(detection.score)\n",
        "#             # print(detection.location_data.relative_bounding_box)\n",
        "#             bboxC = detection.location_data.relative_bounding_box\n",
        "#             ih, iw, ic = img.shape\n",
        "\n",
        "#             # For blur box\n",
        "#             bbox_x = int(bboxC.xmin * iw)\n",
        "#             bbox_y = int(bboxC.ymin * ih)\n",
        "#             old_width = int(bboxC.width * iw)\n",
        "#             old_height = int(bboxC.height * ih)\n",
        "\n",
        "#             # For rectange\n",
        "#             bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "\n",
        "            \n",
        "#             img[bbox_y:bbox_y+old_height,bbox_x:bbox_x+old_width] = cv2.medianBlur( img[bbox_y:bbox_y+old_height,bbox_x:bbox_x+old_width],75)\n",
        "            \n",
        "#             # cv2.rectangle(img, bbox, (255,0,255), 2)\n",
        "\n",
        "#     out.write(img)\n",
        "#     cv2.imshow(\"Video\", img)\n",
        "    \n",
        "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         break"
      ]
    }
  ]
}