{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr7yK4OOQuNnFSG44dosqi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@nimritakoul01/image-processing-using-opencv-python-9c9b83f4b1ca)"
      ],
      "metadata": {
        "id": "9D6hgJM3Slc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMQiSVz2SIao",
        "outputId": "d3214626-9f25-4692-f599-212b92f6755e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "# Installing from within a Jupyter Notebook or Google Colab\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First import the libraries cv2 and matplotlib\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Read an image file using cv2\n",
        "img = cv2.imread(\"path_of_your_imagefile\")\n",
        "\n",
        "# Then below function can display your cv2 image using matplotlib.pyplot.\n",
        "def cv2_imshow(img):\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# You can also configure the figure size and other properties of the display.\n",
        "\n",
        "def cv2_imshow(img):\n",
        "  plt.figure(figsize=(18,18))\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pLexhIhCStn6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image as it is\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread(\"checkerboard_18x18.png\",0) # Read the image as it is\n",
        "cv2_imshow(img)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "APpiSP1_SvQQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread(\"color.jpg\") # Read the image as it is\n",
        "print(\"original image\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "#Convert to grayscale\n",
        "grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "print(\"grayscaled image\")\n",
        "cv2_imshow(grayscale)\n",
        "\n",
        "#Convert grayscale to black and white\n",
        "(thresh, img_bw) = cv2.threshold(grayscale, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "print('black and white image')\n",
        "cv2_imshow(img_bw)"
      ],
      "metadata": {
        "id": "tsRlTLZOSwy3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "# cv2.VideoCapture() allows you to read a video file or capture video from camera.\n",
        "vid_capture = cv2.VideoCapture('veryveryshortvideo.mp4')\n",
        "#Get the frame rate\n",
        "fps = vid_capture.get(5)\n",
        "print('Frames per second : ', fps,'FPS')\n",
        "#get total number of frames\n",
        "frame_count = vid_capture.get(7)\n",
        "print('Frame count : ', frame_count)\n",
        "\n",
        "# Read each frame and display\n",
        "while True:\n",
        "    ret, frame = vid_capture.read()\n",
        "\n",
        "    # Check if the frame is successfully read\n",
        "    if ret:\n",
        "        cv2_imshow(frame)\n",
        "    else:\n",
        "        # Break the loop if no more frames are available\n",
        "        break\n",
        "\n",
        "# Release the video capture object\n",
        "vid_capture.release()\n",
        "# Close all windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "e8QKLUYcSzHG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "def mpl_imshow(img):\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "mpl_imshow(img)"
      ],
      "metadata": {
        "id": "MUleAl1aS1M3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape)\n",
        "\n",
        "#print the entire image array\n",
        "print(img)"
      ],
      "metadata": {
        "id": "_8jk9HsiS2xr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you wish to read an image from Internet, use urllib.request module.\n",
        "import cv2\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "req = urllib.request.urlopen(\"https://raw.githubusercontent.com/NimritaKoul/OpenCV_Tutorial/main/Perfection.png\")\n",
        "arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
        "img = cv2.imdecode(arr, -1) # 'Load it as it is'\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "uNbg_1zpS7Da"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image\n",
        "img = cv2.imread('lion2.jpg')\n",
        "cv2_imshow(img)\n",
        "\n",
        "\n",
        "# Read the image as grayscale\n",
        "img_gray = cv2.imread('lion2.jpg', 0)\n",
        "cv2_imshow(img_gray)"
      ],
      "metadata": {
        "id": "VFfCQ6rQS9HA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(B, G, R) = img[0,0]\n",
        "print(B, G, R)\n",
        "\n",
        "\n",
        "(B, G, R) = img[17,17]\n",
        "print(B, G, R)\n",
        "\n",
        "(B, G, R) = img[17,6]\n",
        "print(B, G, R)"
      ],
      "metadata": {
        "id": "ScQ7hLJgTBRZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read an image as is and display it\n",
        "#Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('lion2.jpg')\n",
        "\n",
        "print(\"Shape of original image\",img.shape)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "V10QxmAnTBpX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Image resizing - downscaling, reducing the size or upscaling , increasing the size\n",
        "new_width = 150\n",
        "new_height = 150\n",
        "new_points = (new_width, new_height)\n",
        "rescaled_img = cv2.resize(img, new_points, interpolation= cv2.INTER_LINEAR)\n",
        "\n",
        "print(\"shape of rescaled image\", rescaled_img.shape)\n",
        "# Display images\n",
        "cv2_imshow(rescaled_img)"
      ],
      "metadata": {
        "id": "JebuEdW-TD9b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Image resizing - downscaling, reducing the size or upscaling , increasing the size\n",
        "new_width = 150\n",
        "new_height = 150\n",
        "new_points = (new_width, new_height)\n",
        "rescaled_img = cv2.resize(img, new_points, interpolation= cv2.INTER_LINEAR)\n",
        "\n",
        "print(\"shape of rescaled image\", rescaled_img.shape)\n",
        "# Display images\n",
        "cv2_imshow(rescaled_img)"
      ],
      "metadata": {
        "id": "hHfk3XFRTGAp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to obtain the center of original image by dividing height and width by 2\n",
        "height, width = img.shape[:2]\n",
        "print(\"Height and width of original image\", height, width)\n",
        "\n",
        "# get the coordinates of the center of the image to create the 2D rotation matrix\n",
        "center = (width/2, height/2)\n",
        "\n",
        "# using cv2.getRotationMatrix2D() to get the rotation matrix\n",
        "rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=180, scale=1)\n",
        "\n",
        "# rotate the image using cv2.warpAffine\n",
        "rotated_image = cv2.warpAffine(src=img, M=rotate_matrix, dsize=(width, height))\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(img)\n",
        "print(\"Rotated Image\")\n",
        "cv2_imshow(rotated_image)"
      ],
      "metadata": {
        "id": "oRjka6DiTHhX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Annotating an image with a line\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Make a copy of the image\n",
        "imageLine1 = img.copy()\n",
        "#Decide the coordinates of the line\n",
        "pointA = (200,180)\n",
        "pointB = (450,500)\n",
        "#cv2.line() draws a line\n",
        "cv2.line(imageLine1, pointA, pointB, (255, 255, 0), thickness=3, lineType=cv2.LINE_AA)\n",
        "\n",
        "#Draw another line from point C to D\n",
        "pointC = (50,50)\n",
        "pointD = (350,300)\n",
        "\n",
        "cv2.line(imageLine1, pointC, pointD, (255, 255, 0), thickness=3, lineType=cv2.LINE_AA)\n",
        "\n",
        "print('Image with line')\n",
        "cv2_imshow(imageLine1)"
      ],
      "metadata": {
        "id": "8eXBKn1zTJvs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Draw a circle on a image\n",
        "#make a copy of the image\n",
        "imageCircle = img.copy()\n",
        "#get the height and width of image\n",
        "height, width = img.shape[:2]\n",
        "print(\"Height and width of original image\", height, width)\n",
        "\n",
        "# get the coordinates of the center of the image\n",
        "center = (width/2, height/2)\n",
        "print(center)\n",
        "# We will draw our circle at the center of the image\n",
        "circle_center = (int(width/2), int(height/2))\n",
        "print(circle_center)\n",
        "\n",
        "# Choose a radius of the circle\n",
        "radius =100\n",
        "# cv2.circle() draws a circle\n",
        "cv2.circle(imageCircle, circle_center, radius, (0, 0, 255), thickness=3, lineType=cv2.LINE_AA)\n",
        "\n",
        "# Show image with circle\n",
        "cv2_imshow(imageCircle)"
      ],
      "metadata": {
        "id": "MTc1aGi8TLYB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Draw a filled circle in the image\n",
        "# make a copy of the original image\n",
        "imageFilledCircle = img.copy()\n",
        "# choose a center for your circle\n",
        "circle_center = (650,150)\n",
        "# choose the radius of the circle\n",
        "radius =100\n",
        "# Draw circle\n",
        "cv2.circle(imageFilledCircle, circle_center, radius, (255, 0, 0), thickness=-1, lineType=cv2.LINE_AA)\n",
        "# SHow image\n",
        "cv2_imshow(imageFilledCircle)"
      ],
      "metadata": {
        "id": "v6d9AxfRTNMo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Drawing a rectangle on the image\n",
        "# make a copy\n",
        "imageRectangle = img.copy()\n",
        "# define the starting and end points of the rectangle\n",
        "start_point =(600,40)\n",
        "end_point =(770,250)\n",
        "# draw the rectangle\n",
        "cv2.rectangle(imageRectangle, start_point, end_point, (0, 0, 255), thickness= 3, lineType=cv2.LINE_8)\n",
        "# display\n",
        "cv2_imshow(imageRectangle)"
      ],
      "metadata": {
        "id": "iwUZozjpTOlU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add text to image\n",
        "imageText = img.copy()\n",
        "text = 'Majestic, Fierce and Free'\n",
        "org = (50,150) #position of text on the image\n",
        "cv2.putText(imageText, text, org, fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 1.5, color = (0,0,0))\n",
        "cv2_imshow(imageText)"
      ],
      "metadata": {
        "id": "a6snyINxTQHu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Working with Color spaces in OpenCV\n",
        "#let us load an image, by default it will have BGR color space\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('lion2.jpg')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "tITjIpnuTRS_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert BGR color space to LAB color space\n",
        "imgLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "cv2_imshow(imgLAB)"
      ],
      "metadata": {
        "id": "WUi-eIXxTYU7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Convert BGR color space to HSV color space\n",
        "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "cv2_imshow(imgHSV)"
      ],
      "metadata": {
        "id": "pjFFXXvsTafv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Let us segment the image using color spaces\n",
        "bgr = [100, 150, 1] #target color in BGR format\n",
        "thresh = 140 #threshold value for color segmentation\n",
        "\n",
        "#lower bound for color segmentation in BGR\n",
        "minBGR = np.array([bgr[0] - thresh, bgr[1] - thresh, bgr[2] - thresh])\n",
        "#upper bound for color segmentation in BGR\n",
        "maxBGR = np.array([bgr[0] + thresh, bgr[1] + thresh, bgr[2] + thresh])\n",
        "#a binary mask where the pixels within a specific range are set to white and others are set to black\n",
        "maskBGR = cv2.inRange(img,minBGR,maxBGR)\n",
        "#do bitwiseAND between image and mask to only keep the pixels in the specified color range\n",
        "resultBGR = cv2.bitwise_and(img, img, mask = maskBGR)\n",
        "cv2_imshow(resultBGR)"
      ],
      "metadata": {
        "id": "bpF3By-JTcPq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Now let us segment the HSV space image\n",
        "#convert 1D array to 3D, then convert it to HSV and take the first element\n",
        "'''\n",
        "np.uint8([[bgr]]) creates a NumPy array of type uint8 containing the BGR color value.\n",
        "However, the cv2.cvtColor() expects an array with shape (1, 1, 3) for a single pixel in BGR format.\n",
        "So, [[bgr]] is used to create a 2D list with one element ([bgr]),\n",
        "and then np.uint8([[bgr]]) converts it to a NumPy array of shape (1, 1, 3).\n",
        "Now, cv2.cvtColor(np.uint8([[bgr]]), cv2.COLOR_BGR2HSV) converts this BGR color to HSV format,\n",
        "resulting in an array with the shape (1, 1, 3), where the third dimension corresponds\n",
        "to the HSV channels (Hue, Saturation, Value).\n",
        "[0][0] is used to get the HSV values of the single pixel (first) in the resulting array.\n",
        "'''\n",
        "hsv = cv2.cvtColor(np.uint8([[bgr]] ), cv2.COLOR_BGR2HSV)[0][0]\n",
        "\n",
        "minHSV = np.array([hsv[0] - thresh, hsv[1] - thresh, hsv[2] - thresh])\n",
        "maxHSV = np.array([hsv[0] + thresh, hsv[1] + thresh, hsv[2] + thresh])\n",
        "\n",
        "maskHSV = cv2.inRange(imgHSV, minHSV, maxHSV)\n",
        "\n",
        "resultHSV = cv2.bitwise_and(imgHSV, imgHSV, mask = maskHSV)\n",
        "\n",
        "cv2_imshow(resultHSV)"
      ],
      "metadata": {
        "id": "55ou-cg8Td43"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Normalization\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def normalize_image(image):\n",
        "    # Convert the image to float32\n",
        "    img_float32 = image.astype(np.float32)\n",
        "\n",
        "    # Normalize the image to the range [100, 200]\n",
        "    # the intensity values of all pixels now will range from 100 to 200 only instead of 0 to 255\n",
        "    normalized_image = cv2.normalize(img_float32, None, 100, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "# Read an image from file\n",
        "img = cv2.imread('lion2.jpg')\n",
        "\n",
        "# Ensure the image is not empty\n",
        "if img is not None:\n",
        "    # Display the original image\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    # Normalize the image\n",
        "    normalized_img = normalize_image(img)\n",
        "\n",
        "    # Display the normalized image\n",
        "    cv2_imshow(normalized_img)"
      ],
      "metadata": {
        "id": "CTnPxSBsThfr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate images similar to an input image (data augmentation)\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "def generate_similar_image(reference_image, noise_factor=0.5):\n",
        "    # Generate random noise from normal distribution\n",
        "    noise = np.random.normal(scale=noise_factor, size=reference_image.shape).astype(np.uint8)\n",
        "\n",
        "    # Add noise to the reference image\n",
        "    similar_image = cv2.add(reference_image, noise)\n",
        "\n",
        "    return similar_image\n",
        "\n",
        "# Read an image from file\n",
        "reference_img = cv2.imread('lion2.jpg')\n",
        "\n",
        "# Ensure the reference image is not empty\n",
        "if reference_img is not None:\n",
        "    # Generate a similar image with random noise\n",
        "    similar_img = generate_similar_image(reference_img)\n",
        "\n",
        "    # Display the original and similar images\n",
        "    cv2_imshow(reference_img)\n",
        "    cv2_imshow(similar_img)"
      ],
      "metadata": {
        "id": "P9_z3LifTipF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Histogram Equalization\n",
        "\n",
        "#Histogram equalization is a technique used to enhance the contrast of an image\n",
        "#by adjusting the intensity values based on the cumulative distribution function\n",
        "#of the pixel intensities.\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read an image from file\n",
        "img = cv2.imread('lion2.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Ensure the image is not empty\n",
        "if img is not None:\n",
        "    # Perform histogram equalization\n",
        "    equalized_img = cv2.equalizeHist(img)\n",
        "\n",
        "    # Display the original and equalized images side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(equalized_img, cmap='gray')\n",
        "    plt.title('Equalized Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: Could not read the image.\")"
      ],
      "metadata": {
        "id": "D7-X5FGfTmtd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Filtering Using Convolution in OpenCV\n",
        "#The identity kernel leaves the image unchanged since it acts as a filter that preserves the original pixel values.\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('lion2.jpg')\n",
        "\n",
        "# define an identity filter or kernel\n",
        "kernel1 = np.array([[0, 0, 0],\n",
        "                    [0, 1, 0],\n",
        "                    [0, 0, 0]])\n",
        "\n",
        "#Apply the kernel to image\n",
        "identity = cv2.filter2D(src=img, ddepth=-1, kernel=kernel1)\n",
        "cv2_imshow(identity)"
      ],
      "metadata": {
        "id": "GSfxNJbhTpyU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Apply blurring kernel\n",
        "#blurring kernel here is a floating point type 5x5 matrix of all 1's, it then normzlizes\n",
        "# values by dividing them by 25 (size of the matrix)\n",
        "\n",
        "#The blurring kernel performs a simple averaging operation over a 5x5 neighborhood,\n",
        "# resulting in a smoothed or blurred version of the image.\n",
        "kernel2 = np.ones((5, 5), np.float32) / 25\n",
        "\n",
        "#apply kernel\n",
        "img = cv2.filter2D(src=img, ddepth=-1, kernel=kernel2)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2.imwrite('blur_kernel.jpg', img)"
      ],
      "metadata": {
        "id": "f9nHeHUiTrbR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Applying Median blur to an image\n",
        "'''\n",
        "Median blur is a type of non-linear filtering.\n",
        "It replaces each pixel value with the median value of its neighborhood.\n",
        "src is the image file, ksize is the kernel size - the size of neighborhood window. It must be an odd integer.\n",
        "'''\n",
        "median = cv2.medianBlur(src=img, ksize=5)\n",
        "cv2_imshow(median)"
      ],
      "metadata": {
        "id": "GEo_RslgTtTW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sharpening an image using a kernel\n",
        "kernel3 = np.array([[0, -1,  0],\n",
        "                   [-1,  5, -1],\n",
        "                    [0, -1,  0]])\n",
        "sharp_img = cv2.filter2D(src=img, ddepth=-1, kernel=kernel3)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(sharp_img)"
      ],
      "metadata": {
        "id": "nIL2FLlxTvXI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bilateral Filtering\n",
        "\n",
        "'''\n",
        "Bilateral filtering is a non-linear filtering technique that preserves edges while reducing noise\n",
        "Arguments of the function bilateralFilter() are,\n",
        "src: The input image.\n",
        "d: Diameter of each pixel neighborhood. It should be an integer,\n",
        "and the neighborhood size is (2 * d + 1) x (2 * d + 1).\n",
        "sigmaColor: Filter sigma in the color space. A larger value of sigmaColor means\n",
        "that farther colors within the pixel neighborhood will be mixed together,\n",
        "producing a more blurred effect in the color space.\n",
        "sigmaSpace: Filter sigma in the coordinate space. A larger value of sigmaSpace\n",
        "means that pixels farther away from the central pixel will have less influence on the filtering.\n",
        "'''\n",
        "\n",
        "bilateral_filter = cv2.bilateralFilter(src=img, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(bilateral_filter)"
      ],
      "metadata": {
        "id": "jGA9LmyWTwsJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Thresholding a grayscale image to black and white\n",
        "'''\n",
        "Image thresholding is a common image processing technique used to separate objects\n",
        "or regions of interest from the background by converting a grayscale image into a binary image.\n",
        "'''\n",
        "img_grayscale = cv2.imread(\"lion2.jpg\", cv2.IMREAD_GRAYSCALE);\n",
        "cv2_imshow(img_grayscale)\n",
        "# Basic threhold example\n",
        "th, dst = cv2.threshold(img_grayscale, 127, 255, cv2.THRESH_BINARY);\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "kSvBWsH7Tzvv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Thresholding a grayscale image to black and white\n",
        "'''\n",
        "Image thresholding is a common image processing technique used to separate objects\n",
        "or regions of interest from the background by converting a grayscale image into a binary image.\n",
        "'''\n",
        "img_grayscale = cv2.imread(\"lion2.jpg\", cv2.IMREAD_GRAYSCALE);\n",
        "cv2_imshow(img_grayscale)\n",
        "# Basic threhold example\n",
        "th, dst = cv2.threshold(img_grayscale, 127, 255, cv2.THRESH_BINARY);\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "rv5OukxoT1qm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholding using THRESH_BINARY_INV\n",
        "'''\n",
        "cv2.THRESH_BINARY_INV creates the inverse of the binary image,\n",
        "where pixel values above the threshold are set to zero, and values below or equal\n",
        "to the threshold are set to a maximum value.\n",
        "'''\n",
        "\n",
        "th, dst = cv2.threshold(img_grayscale,127,255, cv2.THRESH_BINARY_INV)\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "FRQ1vjF8T5d4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholding using THRESH_TRUNC\n",
        "'''\n",
        "This particular thresholding method truncates (sets to the threshold value)\n",
        "pixel values that exceed a specified threshold and leaves the pixel values\n",
        "unchanged if they are below or equal to the threshold.\n",
        "'''\n",
        "th, dst = cv2.threshold(img_grayscale,127,255, cv2.THRESH_TRUNC)\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "b6Nk3lI-T6-m"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholding using THRESH_TOZERO\n",
        "# cv2.THRESH_TOZERO sets pixel values to zero if they are above the threshold else leaves them unchanged\n",
        "\n",
        "th, dst = cv2.threshold(img_grayscale,127,255, cv2.THRESH_TOZERO);\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "BTKswLIzT8-7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholding using THRESH_TOZERO_INV\n",
        "# cv2.THRESH_TOZERO_INV sets pixel values to zero if they are below or equal to the threshold else leaves them unchanged\n",
        "th, dst = cv2.threshold(img_grayscale,127,255, cv2.THRESH_TOZERO_INV);\n",
        "cv2_imshow(dst)"
      ],
      "metadata": {
        "id": "Rq2gDfOkT-9_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('lion2.jpg')\n",
        "# Display original image\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Convert to graycsale\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to the grayscale image using cv2.GaussianBlur\n",
        "# with a kernel size of (3,3) to smooth the image and reduce noise.\n",
        "\n",
        "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
        "\n",
        "# Sobel Edge Detection\n",
        "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Horizontal Edges\n",
        "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Vertical Edges\n",
        "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Horizontal and vertical edges\n",
        "\n",
        "# Display Sobel Edge Detection Images\n",
        "print(\"Sobelx edges\")\n",
        "cv2_imshow(sobelx)\n",
        "print(\"Sobely edges\")\n",
        "cv2_imshow(sobely)\n",
        "print(\"Sobelxy edges\")\n",
        "cv2_imshow(sobelxy)"
      ],
      "metadata": {
        "id": "7KiQPWmdUBTn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('lion2.jpg')\n",
        "# convert the image to grayscale format\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# apply binary thresholding\n",
        "ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n",
        "cv2_imshow(thresh)\n",
        "\n",
        "# detect contours using cv2.findContours() method cv2.CHAIN_APPROX_NONE\n",
        "#cv2.findContours() takes a binary image as input and produces a list of contours along with hierarchy information\n",
        "\n",
        "contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "#make a copy of image\n",
        "image_copy = img.copy()\n",
        "# draw contours on the original image\n",
        "cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
        "cv2_imshow(image_copy)"
      ],
      "metadata": {
        "id": "XYJADYBmUEim"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}