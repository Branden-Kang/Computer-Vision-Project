{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrEFUMLCEn9jRcWlP1Una8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@francescofranco_39234/build-a-resnet-from-scratch-with-tensorflow-and-keras-1b47ba6dd0f5)"
      ],
      "metadata": {
        "id": "m2qkV6yplLFC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wf1agYTwlBc1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Add, GlobalAveragePooling2D,\\\n",
        " Dense, Flatten, Conv2D, Lambda, Input, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import schedules, SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_configuration():\n",
        " \"\"\"\n",
        "  Get configuration variables for the model.\n",
        " \"\"\"\n",
        "\n",
        " # Load dataset for computing dataset size\n",
        " (input_train, _), (_, _) = load_dataset()\n",
        "\n",
        " # Generic config\n",
        " width, height, channels = 32, 32, 3\n",
        " batch_size = 128\n",
        " num_classes = 10\n",
        " validation_split = 0.1 # 45/5 per the He et al. paper\n",
        " verbose = 1\n",
        " n = 3\n",
        " init_fm_dim = 16\n",
        " shortcut_type = \"identity\" # or: projection\n",
        "\n",
        " # Dataset size\n",
        " train_size = (1 - validation_split) * len(input_train)\n",
        " val_size = (validation_split) * len(input_train)\n",
        "\n",
        " # Number of steps per epoch is dependent on batch size\n",
        " maximum_number_iterations = 64000 # per the He et al. paper\n",
        " steps_per_epoch = tensorflow.math.floor(train_size / batch_size)\n",
        " val_steps_per_epoch = tensorflow.math.floor(val_size / batch_size)\n",
        " epochs = tensorflow.cast(tensorflow.math.floor(maximum_number_iterations / steps_per_epoch),\\\n",
        "  dtype=tensorflow.int64)\n",
        "\n",
        " # Define loss function\n",
        " loss = tensorflow.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        " # Learning rate config per the He et al. paper\n",
        " boundaries = [32000, 48000]\n",
        " values = [0.1, 0.01, 0.001]\n",
        " lr_schedule = schedules.PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        " # Set layer init\n",
        " initializer = tensorflow.keras.initializers.HeNormal()\n",
        "\n",
        " # Define optimizer\n",
        " optimizer_momentum = 0.9\n",
        " optimizer_additional_metrics = [\"accuracy\"]\n",
        " optimizer = SGD(learning_rate=lr_schedule, momentum=optimizer_momentum)\n",
        "\n",
        " # Load Tensorboard callback\n",
        " tensorboard = TensorBoard(\n",
        "   log_dir=os.path.join(os.getcwd(), \"logs\"),\n",
        "   histogram_freq=1,\n",
        "   write_images=True\n",
        " )\n",
        "\n",
        " # Save a model checkpoint after every epoch\n",
        " checkpoint = ModelCheckpoint(\n",
        "  os.path.join(os.getcwd(), \"model_checkpoint\"),\n",
        "  save_freq=\"epoch\"\n",
        " )\n",
        "\n",
        " # Add callbacks to list\n",
        " callbacks = [\n",
        "   tensorboard,\n",
        "   checkpoint\n",
        " ]\n",
        "\n",
        " # Create config dictionary\n",
        " config = {\n",
        "  \"width\": width,\n",
        "  \"height\": height,\n",
        "  \"dim\": channels,\n",
        "  \"batch_size\": batch_size,\n",
        "  \"num_classes\": num_classes,\n",
        "  \"validation_split\": validation_split,\n",
        "  \"verbose\": verbose,\n",
        "  \"stack_n\": n,\n",
        "  \"initial_num_feature_maps\": init_fm_dim,\n",
        "  \"training_ds_size\": train_size,\n",
        "  \"steps_per_epoch\": steps_per_epoch,\n",
        "  \"val_steps_per_epoch\": val_steps_per_epoch,\n",
        "  \"num_epochs\": epochs,\n",
        "  \"loss\": loss,\n",
        "  \"optim\": optimizer,\n",
        "  \"optim_learning_rate_schedule\": lr_schedule,\n",
        "  \"optim_momentum\": optimizer_momentum,\n",
        "  \"optim_additional_metrics\": optimizer_additional_metrics,\n",
        "  \"initializer\": initializer,\n",
        "  \"callbacks\": callbacks,\n",
        "  \"shortcut_type\": shortcut_type\n",
        " }\n",
        "\n",
        " return config"
      ],
      "metadata": {
        "id": "dzjXzY1ilOXD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        " \"\"\"\n",
        "  Load the CIFAR-10 dataset\n",
        " \"\"\"\n",
        " return cifar10.load_data()"
      ],
      "metadata": {
        "id": "boIwklzRlQaC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(img, random_crop_size):\n",
        "    # Note: image_data_format is 'channel_last'\n",
        "    # SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "\n",
        "def crop_generator(batches, crop_length):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
        "        yield (batch_crops, batch_y)"
      ],
      "metadata": {
        "id": "hl0rAVsxlRXm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessed_dataset():\n",
        " \"\"\"\n",
        "  Load and preprocess the CIFAR-10 dataset.\n",
        " \"\"\"\n",
        " (input_train, target_train), (input_test, target_test) = load_dataset()\n",
        "\n",
        " # Retrieve shape from model configuration and unpack into components\n",
        " config = model_configuration()\n",
        " width, height, dim = config.get(\"width\"), config.get(\"height\"),\\\n",
        "  config.get(\"dim\")\n",
        " num_classes = config.get(\"num_classes\")\n",
        "\n",
        " # Data augmentation: perform zero padding on datasets\n",
        " paddings = tensorflow.constant([[0, 0,], [4, 4], [4, 4], [0, 0]])\n",
        " input_train = tensorflow.pad(input_train, paddings, mode=\"CONSTANT\")\n",
        "\n",
        " # Convert scalar targets to categorical ones\n",
        " target_train = tensorflow.keras.utils.to_categorical(target_train, num_classes)\n",
        " target_test = tensorflow.keras.utils.to_categorical(target_test, num_classes)\n",
        "\n",
        " # Data generator for training data\n",
        " train_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "  validation_split = config.get(\"validation_split\"),\n",
        "  horizontal_flip = True,\n",
        "  rescale = 1./255,\n",
        "  preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input\n",
        " )\n",
        "\n",
        " # Generate training and validation batches\n",
        " train_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"training\")\n",
        " validation_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"validation\")\n",
        " train_batches = crop_generator(train_batches, config.get(\"height\"))\n",
        " validation_batches = crop_generator(validation_batches, config.get(\"height\"))\n",
        "\n",
        " # Data generator for testing data\n",
        " test_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "  preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input,\n",
        "  rescale = 1./255)\n",
        "\n",
        " # Generate test batches\n",
        " test_batches = test_generator.flow(input_test, target_test, batch_size=config.get(\"batch_size\"))\n",
        "\n",
        " return train_batches, validation_batches, test_batches"
      ],
      "metadata": {
        "id": "96fXFQEDlSy6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, number_of_filters, match_filter_size=False):\n",
        " \"\"\"\n",
        "  Residual block with\n",
        " \"\"\"\n",
        " # Retrieve initializer\n",
        " config = model_configuration()\n",
        " initializer = config.get(\"initializer\")\n",
        "\n",
        " # Create skip connection\n",
        " x_skip = x\n",
        "\n",
        " # Perform the original mapping\n",
        " if match_filter_size:\n",
        "  x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2,2),\\\n",
        "   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        " else:\n",
        "  x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1,1),\\\n",
        "   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        " x = BatchNormalization(axis=3)(x)\n",
        " x = Activation(\"relu\")(x)\n",
        " x = Conv2D(number_of_filters, kernel_size=(3, 3),\\\n",
        "  kernel_initializer=initializer, padding=\"same\")(x)\n",
        " x = BatchNormalization(axis=3)(x)\n",
        "\n",
        " # Perform matching of filter numbers if necessary\n",
        " if match_filter_size and config.get(\"shortcut_type\") == \"identity\":\n",
        "  x_skip = Lambda(lambda x: tensorflow.pad(x[:, ::2, ::2, :], tensorflow.constant([[0, 0,], [0, 0], [0, 0], [number_of_filters//4, number_of_filters//4]]), mode=\"CONSTANT\"))(x_skip)\n",
        " elif match_filter_size and config.get(\"shortcut_type\") == \"projection\":\n",
        "  x_skip = Conv2D(number_of_filters, kernel_size=(1,1),\\\n",
        "   kernel_initializer=initializer, strides=(2,2))(x_skip)\n",
        "\n",
        " # Add the skip connection to the regular mapping\n",
        " x = Add()([x, x_skip])\n",
        "\n",
        " # Nonlinearly activate the result\n",
        " x = Activation(\"relu\")(x)\n",
        "\n",
        " # Return the result\n",
        " return x"
      ],
      "metadata": {
        "id": "kIVFc74llVeB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResidualBlocks(x):\n",
        " \"\"\"\n",
        "  Set up the residual blocks.\n",
        " \"\"\"\n",
        " # Retrieve values\n",
        " config = model_configuration()\n",
        "\n",
        " # Set initial filter size\n",
        " filter_size = config.get(\"initial_num_feature_maps\")\n",
        "\n",
        " # Paper: \"Then we use a stack of 6n layers (...)\n",
        " # with 2n layers for each feature map size.\"\n",
        " # 6n/2n = 3, so there are always 3 groups.\n",
        " for layer_group in range(3):\n",
        "\n",
        "  # Each block in our code has 2 weighted layers,\n",
        "  # and each group has 2n such blocks,\n",
        "  # so 2n/2 = n blocks per group.\n",
        "  for block in range(config.get(\"stack_n\")):\n",
        "\n",
        "   # Perform filter size increase at every\n",
        "   # first layer in the 2nd block onwards.\n",
        "   # Apply Conv block for projecting the skip\n",
        "   # connection.\n",
        "   if layer_group > 0 and block == 0:\n",
        "    filter_size *= 2\n",
        "    x = residual_block(x, filter_size, match_filter_size=True)\n",
        "   else:\n",
        "    x = residual_block(x, filter_size)\n",
        "\n",
        " # Return final layer\n",
        " return x"
      ],
      "metadata": {
        "id": "DayWQa1zlXQe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_base(shp):\n",
        " \"\"\"\n",
        "  Base structure of the model, with residual blocks\n",
        "  attached.\n",
        " \"\"\"\n",
        " # Get number of classes from model configuration\n",
        " config = model_configuration()\n",
        " initializer = model_configuration().get(\"initializer\")\n",
        "\n",
        " # Define model structure\n",
        " # logits are returned because Softmax is pushed to loss function.\n",
        " inputs = Input(shape=shp)\n",
        " x = Conv2D(config.get(\"initial_num_feature_maps\"), kernel_size=(3,3),\\\n",
        "  strides=(1,1), kernel_initializer=initializer, padding=\"same\")(inputs)\n",
        " x = BatchNormalization()(x)\n",
        " x = Activation(\"relu\")(x)\n",
        " x = ResidualBlocks(x)\n",
        " x = GlobalAveragePooling2D()(x)\n",
        " x = Flatten()(x)\n",
        " outputs = Dense(config.get(\"num_classes\"), kernel_initializer=initializer)(x)\n",
        "\n",
        " return inputs, outputs"
      ],
      "metadata": {
        "id": "46nWW2RHlYv9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        " \"\"\"\n",
        "  Initialize a compiled ResNet model.\n",
        " \"\"\"\n",
        " # Get shape from model configuration\n",
        " config = model_configuration()\n",
        "\n",
        " # Get model base\n",
        " inputs, outputs = model_base((config.get(\"width\"), config.get(\"height\"),\\\n",
        "  config.get(\"dim\")))\n",
        "\n",
        " # Initialize and compile model\n",
        " model = Model(inputs, outputs, name=config.get(\"name\"))\n",
        " model.compile(loss=config.get(\"loss\"),\\\n",
        "      optimizer=config.get(\"optim\"),\\\n",
        "       metrics=config.get(\"optim_additional_metrics\"))\n",
        "\n",
        " # Print model summary\n",
        " model.summary()\n",
        "\n",
        " return model"
      ],
      "metadata": {
        "id": "t9lXSHyhlaU3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_batches, validation_batches):\n",
        " \"\"\"\n",
        "  Train an initialized model.\n",
        " \"\"\"\n",
        "\n",
        " # Get model configuration\n",
        " config = model_configuration()\n",
        "\n",
        " # Fit data to model\n",
        " model.fit(train_batches,\n",
        "           batch_size=config.get(\"batch_size\"),\n",
        "           epochs=config.get(\"num_epochs\"),\n",
        "           verbose=config.get(\"verbose\"),\n",
        "           callbacks=config.get(\"callbacks\"),\n",
        "           steps_per_epoch=config.get(\"steps_per_epoch\"),\n",
        "           validation_data=validation_batches,\n",
        "           validation_steps=config.get(\"val_steps_per_epoch\"))\n",
        "\n",
        " return model"
      ],
      "metadata": {
        "id": "aK1tpC_flbif"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_batches):\n",
        " \"\"\"\n",
        "  Evaluate a trained model.\n",
        " \"\"\"\n",
        " # Evaluate model\n",
        " score = model.evaluate(test_batches, verbose=0)\n",
        " print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "id": "qXOs9b5plc7E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_process():\n",
        " \"\"\"\n",
        "  Run the training process for the ResNet model.\n",
        " \"\"\"\n",
        "\n",
        " # Get dataset\n",
        " train_batches, validation_batches, test_batches = preprocessed_dataset()\n",
        "\n",
        " # Initialize ResNet\n",
        " resnet = init_model()\n",
        "\n",
        " # Train ResNet model\n",
        " trained_resnet = train_model(resnet, train_batches, validation_batches)\n",
        "\n",
        " # Evalute trained ResNet model post training\n",
        " evaluate_model(trained_resnet, test_batches)"
      ],
      "metadata": {
        "id": "iJ535Xlaldqy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        " training_process()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiCda736le3s",
        "outputId": "98520a10-38bc-48de-c666-1167420f9934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 16)           64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 16)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 16)           2320      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 16)           64        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 16)           64        ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 16)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    , 'activation[0][0]']         \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 16)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 16)           64        ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 16)           64        ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 16)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    , 'activation_2[0][0]']       \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 32, 32, 16)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 16)           64        ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 16)           64        ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 32, 32, 16)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'activation_4[0][0]']       \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 16)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 32)           4640      ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 32)           128       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)           9248      ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 32)           128       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 16, 16, 32)           0         ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    , 'lambda[0][0]']             \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 16, 16, 32)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 32)           9248      ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 32)           128       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 32)           128       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 32)           0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 32)           128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 32)           128       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 16, 16, 32)           0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 64)             18496     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 8, 8, 64)             256       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 8, 8, 64)             256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 8, 8, 64)             0         ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_14[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 8, 8, 64)             0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 64)             256       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 8, 8, 64)             256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 8, 8, 64)             0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 8, 8, 64)             256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 64)             256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_18[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 8, 8, 64)             0         ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['activation_18[0][0]']       \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   650       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 271786 (1.04 MB)\n",
            "Trainable params: 270410 (1.03 MB)\n",
            "Non-trainable params: 1376 (5.38 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/182\n",
            " 77/351 [=====>........................] - ETA: 7:10 - loss: 2.4396 - accuracy: 0.1883"
          ]
        }
      ]
    }
  ]
}